//! Cross-verification tests for Zolt compatibility
//!
//! This module provides tests to verify that proofs generated by Zolt
//! can be verified by Jolt's verifier.
//!
//! ## Usage
//!
//! 1. Generate reference preprocessing in Jolt:
//!    ```bash
//!    cargo run --example fibonacci -- --save
//!    # This creates /tmp/jolt_verifier_preprocessing.dat
//!    ```
//!
//! 2. Generate proof in Zolt using the same program:
//!    ```bash
//!    cd /path/to/zolt
//!    zig build -Doptimize=ReleaseFast
//!    ./zig-out/bin/zolt prove fibonacci.elf --jolt-format -o /tmp/zolt_proof.bin
//!    ```
//!
//! 3. Run cross-verification test:
//!    ```bash
//!    cargo test zolt_compat
//!    ```

#[cfg(test)]
mod tests {
    use crate::zkvm::Serializable;
    use crate::subprotocols::sumcheck::SumcheckInstanceProof;
    use crate::subprotocols::univariate_skip::UniSkipFirstRoundProof;
    use crate::transcripts::Blake2bTranscript;
    use crate::poly::commitment::dory::DoryCommitmentScheme;
    use crate::poly::commitment::commitment_scheme::CommitmentScheme;
    type DoryCommitment = <DoryCommitmentScheme as CommitmentScheme>::Commitment;
    use ark_bn254::Fr;
    use std::fs;
    use std::path::Path;

    /// Test that we can deserialize a Zolt-generated proof
    ///
    /// This test demonstrates the basic deserialization capability.
    /// It requires a Zolt proof file at /tmp/zolt_proof_dory.bin
    #[test]
    #[ignore = "requires Zolt proof file - run manually"]
    fn test_deserialize_zolt_proof() {
        use crate::zkvm::RV64IMACProof;

        let proof_path = "/tmp/zolt_proof_dory.bin";
        if !Path::new(proof_path).exists() {
            println!("Skipping test: Zolt proof not found at {}", proof_path);
            println!("Generate with: ./zolt prove program.elf --jolt-format -o {}", proof_path);
            return;
        }

        let proof_bytes = fs::read(proof_path).expect("Failed to read Zolt proof");
        println!("Read {} bytes from Zolt proof", proof_bytes.len());

        // Try to deserialize
        match RV64IMACProof::deserialize_from_bytes(&proof_bytes) {
            Ok(proof) => {
                println!("Successfully deserialized Zolt proof!");
                println!("  Trace length: {}", proof.trace_length);
                println!("  RAM K: {}", proof.ram_K);
                println!("  Bytecode K: {}", proof.bytecode_K);
                println!("  Commitments: {}", proof.commitments.len());
            }
            Err(e) => {
                panic!("Failed to deserialize Zolt proof: {:?}", e);
            }
        }
    }

    /// Test full cross-verification with Zolt proof
    ///
    /// Requires:
    /// - /tmp/jolt_verifier_preprocessing.dat (from Jolt)
    /// - /tmp/zolt_proof.bin (from Zolt)
    /// - /tmp/fib_io_device.bin (from Jolt)
    #[test]
    #[ignore = "requires full Zolt proof setup - run manually"]
    fn test_verify_zolt_proof() {
        use crate::zkvm::{RV64IMACProof, RV64IMACVerifier};
        use common::jolt_device::JoltDevice;

        // Check required files exist
        let preprocessing_path = "/tmp/jolt_verifier_preprocessing.dat";
        let proof_path = "/tmp/zolt_proof_dory.bin";
        let io_path = "/tmp/fib_io_device.bin";

        for path in [preprocessing_path, proof_path, io_path] {
            if !Path::new(path).exists() {
                println!("Missing required file: {}", path);
                println!("\nTo generate Jolt files:");
                println!("  cargo run --example fibonacci -- --save");
                println!("\nTo generate Zolt proof:");
                println!("  ./zolt prove fibonacci.elf --jolt-format -o {}", proof_path);
                return;
            }
        }

        // Load verifier preprocessing
        let preprocessing_bytes = fs::read(preprocessing_path)
            .expect("Failed to read verifier preprocessing");
        let preprocessing = crate::zkvm::verifier::JoltVerifierPreprocessing::deserialize_from_bytes(
            &preprocessing_bytes,
        )
        .expect("Failed to deserialize preprocessing");

        // Load Zolt proof
        let proof_bytes = fs::read(proof_path).expect("Failed to read Zolt proof");
        let proof = RV64IMACProof::deserialize_from_bytes(&proof_bytes)
            .expect("Failed to deserialize proof");

        // Load program I/O
        let io_bytes = fs::read(io_path).expect("Failed to read program I/O");
        let program_io = JoltDevice::deserialize_from_bytes(&io_bytes)
            .expect("Failed to deserialize program I/O");

        println!("Loaded all files, attempting verification...");
        println!("  Proof trace length: {}", proof.trace_length);
        println!("  Proof commitments: {}", proof.commitments.len());
        println!("  Opening claims count: {}", proof.opening_claims.0.len());

        // Debug: print all opening claims
        println!("  Opening claims:");
        for (key, (_point, claim)) in &proof.opening_claims.0 {
            println!("    {:?} => {:?}", key, claim);
        }

        // Debug: print proof structure details
        println!("\n  Stage 1 UniSkip proof:");
        println!("    uni_poly coeffs count: {}", proof.stage1_uni_skip_first_round_proof.uni_poly.coeffs.len());
        if proof.stage1_uni_skip_first_round_proof.uni_poly.coeffs.len() >= 3 {
            println!("    first 3 coeffs: {:?}, {:?}, {:?}",
                proof.stage1_uni_skip_first_round_proof.uni_poly.coeffs[0],
                proof.stage1_uni_skip_first_round_proof.uni_poly.coeffs[1],
                proof.stage1_uni_skip_first_round_proof.uni_poly.coeffs[2]);
        }

        println!("  Stage 1 sumcheck proof:");
        println!("    compressed_polys count: {}", proof.stage1_sumcheck_proof.compressed_polys.len());
        for (i, poly) in proof.stage1_sumcheck_proof.compressed_polys.iter().enumerate().take(3) {
            println!("    round {} coeffs: {:?}", i, poly.coeffs_except_linear_term);
        }

        // Create verifier
        match RV64IMACVerifier::new(
            &preprocessing,
            proof,
            program_io,
            None, // no trusted advice
            None, // no debug info
        ) {
            Ok(verifier) => {
                println!("Verifier created successfully, running verification...");
                match verifier.verify() {
                    Ok(()) => {
                        println!("SUCCESS: Zolt proof verified by Jolt!");
                    }
                    Err(e) => {
                        panic!("Verification failed: {:?}", e);
                    }
                }
            }
            Err(e) => {
                panic!("Failed to create verifier: {:?}", e);
            }
        }
    }

    /// Test loading Zolt-exported preprocessing
    ///
    /// This test verifies that Zolt can export preprocessing that Jolt can load.
    /// Requires:
    /// - /tmp/zolt_preprocessing.bin (from Zolt with --export-preprocessing)
    #[test]
    #[ignore = "requires Zolt preprocessing export - run manually"]
    fn test_load_zolt_preprocessing() {
        use crate::zkvm::verifier::JoltVerifierPreprocessing;
        use crate::poly::commitment::dory::DoryCommitmentScheme;

        type PreprocessingType = JoltVerifierPreprocessing<ark_bn254::Fr, DoryCommitmentScheme>;

        let preprocessing_path = "/tmp/zolt_preprocessing.bin";
        if !Path::new(preprocessing_path).exists() {
            println!("Missing Zolt preprocessing file at {}", preprocessing_path);
            println!("\nGenerate with:");
            println!("  ./zolt prove examples/fibonacci.elf --export-preprocessing {} -o proof.bin",
                preprocessing_path);
            return;
        }

        let preprocessing_bytes = fs::read(preprocessing_path)
            .expect("Failed to read Zolt preprocessing");
        println!("Read {} bytes from Zolt preprocessing", preprocessing_bytes.len());

        // Dump first 200 bytes for debugging
        println!("First 200 bytes:");
        for (i, chunk) in preprocessing_bytes[..std::cmp::min(200, preprocessing_bytes.len())].chunks(16).enumerate() {
            print!("{:04x}: ", i * 16);
            for b in chunk {
                print!("{:02x} ", b);
            }
            println!();
        }

        // Try to deserialize
        match PreprocessingType::deserialize_from_bytes(&preprocessing_bytes) {
            Ok(preprocessing) => {
                println!("Successfully deserialized Zolt preprocessing!");
                println!("  Memory layout: {:?}", preprocessing.shared.memory_layout);
                println!("  Bytecode size: {}", preprocessing.shared.bytecode.code_size);
                println!("  RAM min_bytecode_address: {}", preprocessing.shared.ram.min_bytecode_address);
            }
            Err(e) => {
                println!("Failed to deserialize Zolt preprocessing: {:?}", e);

                // Try to parse just the verifier setup to debug
                println!("\nTrying to parse verifier setup separately...");
                use ark_serialize::CanonicalDeserialize;
                use crate::poly::commitment::dory::ArkworksVerifierSetup;

                match ArkworksVerifierSetup::deserialize_uncompressed(&preprocessing_bytes[..]) {
                    Ok(setup) => {
                        println!("  Verifier setup parsed OK!");
                        println!("  max_log_n: {}", setup.0.max_log_n);
                        println!("  delta_1l len: {}", setup.0.delta_1l.len());
                        println!("  chi len: {}", setup.0.chi.len());
                    }
                    Err(e2) => {
                        println!("  Failed to parse verifier setup: {:?}", e2);
                    }
                }

                panic!("Deserialization failed: {:?}", e);
            }
        }
    }

    /// Test verification with Zolt-exported proof AND preprocessing
    ///
    /// This is the full cross-verification test where both proof and preprocessing
    /// come from Zolt.
    ///
    /// Requires:
    /// - /tmp/zolt_preprocessing.bin (from Zolt with --export-preprocessing)
    /// - /tmp/zolt_proof_dory.bin (from Zolt)
    #[test]
    #[ignore = "requires Zolt proof and preprocessing - run manually"]
    fn test_verify_zolt_proof_with_zolt_preprocessing() {
        use crate::zkvm::{RV64IMACProof, RV64IMACVerifier};
        use crate::zkvm::verifier::JoltVerifierPreprocessing;
        use crate::poly::commitment::dory::DoryCommitmentScheme;
        use common::jolt_device::JoltDevice;

        type PreprocessingType = JoltVerifierPreprocessing<ark_bn254::Fr, DoryCommitmentScheme>;

        // Try local logs dir first, then fall back to /tmp
        let logs_dir = std::env::var("ZOLT_LOGS_DIR").unwrap_or_else(|_| {
            // Look for ../zolt/logs relative to jolt repo
            let local_logs = std::path::Path::new("../zolt/logs");
            if local_logs.exists() {
                local_logs.to_string_lossy().to_string()
            } else {
                "/tmp".to_string()
            }
        });
        let preprocessing_path = format!("{}/zolt_preprocessing.bin", logs_dir);
        let proof_path = format!("{}/zolt_proof_dory.bin", logs_dir);

        println!("Using logs_dir: {}", logs_dir);
        println!("Proof path: {}", proof_path);

        // Check files exist
        for path in [preprocessing_path.as_str(), proof_path.as_str()] {
            if !Path::new(path).exists() {
                println!("Missing required file: {}", path);
                println!("\nGenerate with:");
                println!("  ./zolt prove examples/fibonacci.elf \\");
                println!("    --export-preprocessing {} \\", preprocessing_path);
                println!("    -o {}", proof_path);
                return;
            }
        }

        // Load preprocessing
        let preprocessing_bytes = fs::read(&preprocessing_path)
            .expect("Failed to read preprocessing");
        let mut pp_cursor = std::io::Cursor::new(&preprocessing_bytes);
        let preprocessing = PreprocessingType::deserialize_compressed(&mut pp_cursor)
            .expect("Failed to deserialize preprocessing");

        // Check for appended raw instruction words (Zolt-specific extension)
        // Format: magic "ZOLT_RAW\n" (9 bytes) + count (u64 LE) + count * u32 LE words
        {
            let pos = pp_cursor.position() as usize;
            let remaining = &preprocessing_bytes[pos..];
            if remaining.len() >= 9 && &remaining[..9] == b"ZOLT_RAW\n" {
                let mut offset = 9;
                let count = u64::from_le_bytes(remaining[offset..offset+8].try_into().unwrap()) as usize;
                offset += 8;
                let mut raw_words = Vec::with_capacity(count);
                for i in 0..count {
                    let word = u32::from_le_bytes(remaining[offset + i*4..offset + i*4 + 4].try_into().unwrap());
                    raw_words.push(word);
                }
                offset += count * 4;
                let termination_base_pc = u64::from_le_bytes(remaining[offset..offset+8].try_into().unwrap()) as usize;
                println!("Loaded {} raw instruction words from preprocessing (termination_base_pc={})", count, termination_base_pc);
                // Set the globals so compute_val_polys_zolt is used
                let _ = crate::zkvm::bytecode::ZOLT_RAW_WORDS.set(raw_words);
                // Set termination address from preprocessing memory layout
                let term_addr = preprocessing.shared.memory_layout.termination;
                let _ = crate::zkvm::bytecode::ZOLT_TERMINATION_ADDRESS.set(term_addr);
                let _ = crate::zkvm::bytecode::ZOLT_TERMINATION_BASE_PC.set(termination_base_pc);
                println!("Set ZOLT_TERMINATION_ADDRESS = 0x{:x}, ZOLT_TERMINATION_BASE_PC = {}", term_addr, termination_base_pc);
            } else {
                println!("No raw instruction words found in preprocessing (pos={}, remaining={})", pos, remaining.len());
            }
        }

        // Load proof
        let proof_bytes = fs::read(proof_path).expect("Failed to read proof");
        println!("Proof bytes: {} bytes", proof_bytes.len());
        println!("First 100 bytes (hex): {}", proof_bytes.iter().take(100).map(|b| format!("{:02x}", b)).collect::<Vec<_>>().join(" "));

        // Try to debug deserialization incrementally
        use std::io::Cursor;
        use ark_serialize::CanonicalDeserialize;
        use crate::zkvm::proof_serialization::Claims;

        let mut cursor = Cursor::new(&proof_bytes);

        // 1. Parse opening claims
        println!("\n=== Parsing Opening Claims ===");

        // Debug: print bytes at expected LookupTableFlag(0) position
        let offset = 0xd74usize;
        println!("Bytes at 0x{:x}: {:02x?}", offset, &proof_bytes[offset..offset+32]);

        let claims: Claims<Fr> = match Claims::deserialize_compressed(&mut cursor) {
            Ok(c) => {
                println!("Successfully parsed {} opening claims", c.0.len());
                c
            },
            Err(e) => {
                println!("Failed to parse opening claims at byte {}: {:?}", cursor.position(), e);
                panic!("Failed at opening claims");
            }
        };

        // 2. Parse commitments
        println!("\n=== Parsing Commitments ===");
        println!("Starting at byte: 0x{:x}", cursor.position());

        // Read length first
        let comm_len = {
            use std::io::Read;
            let mut len_bytes = [0u8; 8];
            cursor.read_exact(&mut len_bytes).expect("read len");
            u64::from_le_bytes(len_bytes)
        };
        println!("Commitments length: {}", comm_len);

        // Try to parse each GT element
        for i in 0..comm_len {
            let pos = cursor.position();
            println!("Parsing commitment {} at 0x{:x}", i, pos);
            let gt: DoryCommitment = match DoryCommitment::deserialize_compressed(&mut cursor) {
                Ok(g) => g,
                Err(e) => {
                    println!("Failed at commitment {} (byte 0x{:x}): {:?}", i, pos, e);
                    let pos_usize = pos as usize;
                    println!("Bytes: {:02x?}", &proof_bytes[pos_usize..std::cmp::min(pos_usize+50, proof_bytes.len())]);
                    panic!("Failed at commitment");
                }
            };
            if i < 3 {
                println!("  Commitment {} OK", i);
            }
        }
        println!("All {} commitments parsed OK, now at 0x{:x}", comm_len, cursor.position());

        // Reset cursor and use Vec deserialize
        cursor.set_position(cursor.position() - (comm_len * 384 + 8));
        let commitments: Vec<DoryCommitment> = match Vec::deserialize_compressed(&mut cursor) {
            Ok(c) => {
                println!("Successfully parsed {} commitments via Vec", c.len());
                c
            },
            Err(e) => {
                println!("Failed to parse commitments at byte {}: {:?}", cursor.position(), e);
                let pos = cursor.position() as usize;
                println!("Bytes at error position: {:?}", &proof_bytes[pos..std::cmp::min(pos+50, proof_bytes.len())]);
                panic!("Failed at commitments");
            }
        };

        // 3. Parse Stage 1 UniSkip
        println!("\n=== Parsing Stage 1 UniSkip ===");
        println!("Starting at byte: {}", cursor.position());
        let stage1_uniskip: UniSkipFirstRoundProof<Fr, Blake2bTranscript> = match UniSkipFirstRoundProof::deserialize_compressed(&mut cursor) {
            Ok(p) => {
                println!("Successfully parsed stage1 uniskip");
                p
            },
            Err(e) => {
                println!("Failed to parse stage1 uniskip at byte {}: {:?}", cursor.position(), e);
                panic!("Failed at stage1 uniskip");
            }
        };

        // 4. Parse Stage 1 Sumcheck
        println!("\n=== Parsing Stage 1 Sumcheck ===");
        println!("Starting at byte: {}", cursor.position());
        let stage1_sumcheck: SumcheckInstanceProof<Fr, Blake2bTranscript> = match SumcheckInstanceProof::deserialize_compressed(&mut cursor) {
            Ok(p) => {
                println!("Successfully parsed stage1 sumcheck with {} rounds", p.compressed_polys.len());
                p
            },
            Err(e) => {
                println!("Failed to parse stage1 sumcheck at byte {}: {:?}", cursor.position(), e);
                panic!("Failed at stage1 sumcheck");
            }
        };

        // Continue parsing all remaining fields
        println!("\n=== Parsing Stage 2 UniSkip ===");
        println!("Starting at byte: 0x{:x}", cursor.position());
        let stage2_uniskip: UniSkipFirstRoundProof<Fr, Blake2bTranscript> = match UniSkipFirstRoundProof::deserialize_compressed(&mut cursor) {
            Ok(p) => {
                println!("Successfully parsed stage2 uniskip");
                p
            },
            Err(e) => {
                println!("Failed to parse stage2 uniskip at byte 0x{:x}: {:?}", cursor.position(), e);
                let pos = cursor.position() as usize;
                println!("Bytes: {:02x?}", &proof_bytes[pos..std::cmp::min(pos+50, proof_bytes.len())]);
                panic!("Failed at stage2 uniskip");
            }
        };

        println!("\n=== Parsing Stage 2 Sumcheck ===");
        println!("Starting at byte: 0x{:x}", cursor.position());
        let stage2_sumcheck: SumcheckInstanceProof<Fr, Blake2bTranscript> = match SumcheckInstanceProof::deserialize_compressed(&mut cursor) {
            Ok(p) => {
                println!("Successfully parsed stage2 sumcheck with {} rounds", p.compressed_polys.len());
                p
            },
            Err(e) => {
                println!("Failed to parse stage2 sumcheck at byte 0x{:x}: {:?}", cursor.position(), e);
                panic!("Failed at stage2 sumcheck");
            }
        };

        println!("\n=== Parsing Stage 3 Sumcheck ===");
        println!("Starting at byte: 0x{:x}", cursor.position());
        let stage3_sumcheck: SumcheckInstanceProof<Fr, Blake2bTranscript> = match SumcheckInstanceProof::deserialize_compressed(&mut cursor) {
            Ok(p) => {
                println!("Successfully parsed stage3 sumcheck with {} rounds", p.compressed_polys.len());
                p
            },
            Err(e) => {
                println!("Failed to parse stage3 sumcheck at byte 0x{:x}: {:?}", cursor.position(), e);
                panic!("Failed at stage3 sumcheck");
            }
        };

        println!("\n=== Parsing Stage 4 Sumcheck ===");
        println!("Starting at byte: 0x{:x}", cursor.position());
        let stage4_sumcheck: SumcheckInstanceProof<Fr, Blake2bTranscript> = match SumcheckInstanceProof::deserialize_compressed(&mut cursor) {
            Ok(p) => {
                println!("Successfully parsed stage4 sumcheck with {} rounds", p.compressed_polys.len());
                p
            },
            Err(e) => {
                println!("Failed to parse stage4 sumcheck at byte 0x{:x}: {:?}", cursor.position(), e);
                panic!("Failed at stage4 sumcheck");
            }
        };

        println!("\n=== Parsing Stage 5 Sumcheck ===");
        println!("Starting at byte: 0x{:x}", cursor.position());
        let stage5_sumcheck: SumcheckInstanceProof<Fr, Blake2bTranscript> = match SumcheckInstanceProof::deserialize_compressed(&mut cursor) {
            Ok(p) => {
                println!("Successfully parsed stage5 sumcheck with {} rounds", p.compressed_polys.len());
                p
            },
            Err(e) => {
                println!("Failed to parse stage5 sumcheck at byte 0x{:x}: {:?}", cursor.position(), e);
                panic!("Failed at stage5 sumcheck");
            }
        };

        println!("\n=== Parsing Stage 6 Sumcheck ===");
        println!("Starting at byte: 0x{:x}", cursor.position());
        let stage6_sumcheck: SumcheckInstanceProof<Fr, Blake2bTranscript> = match SumcheckInstanceProof::deserialize_compressed(&mut cursor) {
            Ok(p) => {
                println!("Successfully parsed stage6 sumcheck with {} rounds", p.compressed_polys.len());
                p
            },
            Err(e) => {
                println!("Failed to parse stage6 sumcheck at byte 0x{:x}: {:?}", cursor.position(), e);
                panic!("Failed at stage6 sumcheck");
            }
        };

        println!("\n=== Parsing Stage 7 Sumcheck ===");
        println!("Starting at byte: 0x{:x}", cursor.position());
        let stage7_sumcheck: SumcheckInstanceProof<Fr, Blake2bTranscript> = match SumcheckInstanceProof::deserialize_compressed(&mut cursor) {
            Ok(p) => {
                println!("Successfully parsed stage7 sumcheck with {} rounds", p.compressed_polys.len());
                p
            },
            Err(e) => {
                println!("Failed to parse stage7 sumcheck at byte 0x{:x}: {:?}", cursor.position(), e);
                panic!("Failed at stage7 sumcheck");
            }
        };

        println!("\n=== Parsing Joint Opening Proof ===");
        println!("Starting at byte: 0x{:x}", cursor.position());
        println!("Bytes at cursor: {:02x?}", &proof_bytes[cursor.position() as usize..std::cmp::min(cursor.position() as usize + 50, proof_bytes.len())]);

        use crate::poly::commitment::dory::ArkDoryProof;
        // Debug: manually parse Dory proof element-by-element
        {
            let save_pos = cursor.position();
            use ark_bn254::{Fq12, G1Projective, G2Projective};
            // VMV message
            let c: Fq12 = match CanonicalDeserialize::deserialize_compressed(&mut cursor) {
                Ok(v) => { println!("  VMV.c OK at 0x{:x}", save_pos); v },
                Err(e) => { println!("  VMV.c FAIL at 0x{:x}: {:?}", cursor.position(), e); panic!("FAIL"); }
            };
            let d2: Fq12 = match CanonicalDeserialize::deserialize_compressed(&mut cursor) {
                Ok(v) => { println!("  VMV.d2 OK"); v },
                Err(e) => { println!("  VMV.d2 FAIL at 0x{:x}: {:?}", cursor.position(), e); panic!("FAIL"); }
            };
            let e1: G1Projective = match CanonicalDeserialize::deserialize_compressed(&mut cursor) {
                Ok(v) => { println!("  VMV.e1 OK"); v },
                Err(e) => { println!("  VMV.e1 FAIL at 0x{:x}: {:?}", cursor.position(), e); panic!("FAIL"); }
            };
            let num_rounds: u32 = match CanonicalDeserialize::deserialize_compressed(&mut cursor) {
                Ok(v) => { println!("  num_rounds: {}", v); v },
                Err(e) => { println!("  num_rounds FAIL: {:?}", e); panic!("FAIL"); }
            };
            for r in 0..num_rounds {
                for name in ["d1_left", "d1_right", "d2_left", "d2_right"] {
                    let _gt: Fq12 = match CanonicalDeserialize::deserialize_compressed(&mut cursor) {
                        Ok(v) => v,
                        Err(e) => { println!("  first_messages[{}].{} FAIL at 0x{:x}: {:?}", r, name, cursor.position(), e); panic!("FAIL"); }
                    };
                }
                let _g1: G1Projective = match CanonicalDeserialize::deserialize_compressed(&mut cursor) {
                    Ok(v) => v,
                    Err(e) => { println!("  first_messages[{}].e1_beta FAIL at 0x{:x}: {:?}", r, cursor.position(), e); panic!("FAIL"); }
                };
                let _g2: G2Projective = match CanonicalDeserialize::deserialize_compressed(&mut cursor) {
                    Ok(v) => v,
                    Err(e) => { println!("  first_messages[{}].e2_beta FAIL at 0x{:x}: {:?}", r, cursor.position(), e); panic!("FAIL"); }
                };
                println!("  first_messages[{}] OK (cursor 0x{:x})", r, cursor.position());
            }
            for r in 0..num_rounds {
                for name in ["c_plus", "c_minus"] {
                    let _gt: Fq12 = match CanonicalDeserialize::deserialize_compressed(&mut cursor) {
                        Ok(v) => v,
                        Err(e) => { println!("  second_messages[{}].{} FAIL at 0x{:x}: {:?}", r, name, cursor.position(), e); panic!("FAIL"); }
                    };
                }
                for name in ["e1_plus", "e1_minus"] {
                    let _g1: G1Projective = match CanonicalDeserialize::deserialize_compressed(&mut cursor) {
                        Ok(v) => v,
                        Err(e) => { println!("  second_messages[{}].{} FAIL at 0x{:x}: {:?}", r, name, cursor.position(), e); panic!("FAIL"); }
                    };
                }
                for name in ["e2_plus", "e2_minus"] {
                    let _g2: G2Projective = match CanonicalDeserialize::deserialize_compressed(&mut cursor) {
                        Ok(v) => v,
                        Err(e) => { println!("  second_messages[{}].{} FAIL at 0x{:x}: {:?}", r, name, cursor.position(), e); panic!("FAIL"); }
                    };
                }
                println!("  second_messages[{}] OK (cursor 0x{:x})", r, cursor.position());
            }
            println!("  All Dory elements parsed OK!");
            cursor.set_position(save_pos);
        }
        let opening_proof: ArkDoryProof = match ArkDoryProof::deserialize_compressed(&mut cursor) {
            Ok(p) => {
                println!("Successfully parsed opening proof");
                p
            },
            Err(e) => {
                println!("Failed to parse opening proof at byte 0x{:x}: {:?}", cursor.position(), e);
                panic!("Failed at opening proof");
            }
        };

        println!("\n=== All parsing succeeded! ===");
        println!("Final cursor position: 0x{:x}", cursor.position());
        println!("Bytes remaining: {}", proof_bytes.len() - cursor.position() as usize);

        // Try full proof deserialization
        let proof = RV64IMACProof::deserialize_from_bytes(&proof_bytes)
            .expect("Failed to deserialize proof");

        // Create minimal program I/O (no inputs/outputs for bare-metal fibonacci)
        let program_io = JoltDevice {
            memory_layout: preprocessing.shared.memory_layout.clone(),
            ..Default::default()
        };

        println!("Loaded all files:");
        println!("  Preprocessing: {} bytes", preprocessing_bytes.len());
        println!("  Proof: {} bytes", proof_bytes.len());
        println!("  Trace length: {}", proof.trace_length);
        println!("  ram_K: {} (log2 = {})", proof.ram_K, proof.ram_K.ilog2());
        println!("  bytecode_K: {} (log2 = {})", proof.bytecode_K, proof.bytecode_K.ilog2());
        println!("  Commitments: {}", proof.commitments.len());

        // Create verifier
        match RV64IMACVerifier::new(
            &preprocessing,
            proof,
            program_io,
            None, // no trusted advice
            None, // no debug info
        ) {
            Ok(verifier) => {
                println!("Verifier created, running verification...");
                match verifier.verify() {
                    Ok(()) => {
                        println!("SUCCESS: Zolt proof verified by Jolt!");
                    }
                    Err(e) => {
                        println!("Verification failed: {:?}", e);
                    }
                }
            }
            Err(e) => {
                println!("Failed to create verifier: {:?}", e);
            }
        }
    }

    /// Test GT (Dory commitment) serialization size
    #[test]
    fn test_gt_serialization_size() {
        use ark_serialize::CanonicalSerialize;
        use ark_bn254::Fq12;
        use ark_ff::One;

        // Fq12 is the target group for BN254 pairing
        let gt = Fq12::one();
        let mut bytes = Vec::new();
        gt.serialize_compressed(&mut bytes).expect("serialize");
        println!("Fq12 (GT) compressed size: {} bytes", bytes.len());

        bytes.clear();
        gt.serialize_uncompressed(&mut bytes).expect("serialize");
        println!("Fq12 (GT) uncompressed size: {} bytes", bytes.len());

        // Dump first bytes
        println!("First bytes: {:02x?}", &bytes[..std::cmp::min(64, bytes.len())]);
    }

    /// Minimal test to verify byte format compatibility
    ///
    /// This generates a proof in Jolt, serializes it, and verifies
    /// we can deserialize it back - establishing the baseline format.
    #[test]
    fn test_jolt_proof_roundtrip() {
        // This test uses internal Jolt functions to verify
        // our understanding of the serialization format is correct
        use ark_serialize::{CanonicalDeserialize, CanonicalSerialize};

        // Test basic field element serialization
        use ark_bn254::Fr;
        use ark_ff::One;

        let fe = Fr::one();
        let mut bytes = Vec::new();
        fe.serialize_compressed(&mut bytes).expect("serialize");
        assert_eq!(bytes.len(), 32, "Fr should serialize to 32 bytes");

        let fe2 = Fr::deserialize_compressed(&bytes[..]).expect("deserialize");
        assert_eq!(fe, fe2, "Roundtrip should preserve value");

        println!("Basic field element roundtrip: OK");
    }

    /// Debug test to see what format Zolt is producing
    #[test]
    #[ignore = "debug test for format analysis"]
    fn test_debug_zolt_format() {
        use ark_serialize::CanonicalDeserialize;
        use ark_bn254::Fr;
        use crate::poly::opening_proof::SumcheckId;
        use strum::EnumCount;

        // Use the new Dory proof
        let proof_path = "/tmp/zolt_proof_dory.bin";
        if !Path::new(proof_path).exists() {
            println!("No proof file at {}", proof_path);
            return;
        }

        let proof_bytes = fs::read(proof_path).expect("Failed to read Zolt proof");
        println!("Total bytes: {}", proof_bytes.len());
        println!("SumcheckId::COUNT = {}", SumcheckId::COUNT);

        // Dump first 200 bytes in hex
        println!("\nFirst 200 bytes:");
        for (i, chunk) in proof_bytes[..std::cmp::min(200, proof_bytes.len())].chunks(16).enumerate() {
            print!("{:04x}: ", i * 16);
            for b in chunk {
                print!("{:02x} ", b);
            }
            println!();
        }

        // Constants matching Jolt
        let untrusted_advice_base: u8 = 0;
        let trusted_advice_base: u8 = SumcheckId::COUNT as u8;  // 22
        let committed_base: u8 = trusted_advice_base + SumcheckId::COUNT as u8;  // 44
        let virtual_base: u8 = committed_base + SumcheckId::COUNT as u8;  // 66

        println!("\nBases: untrusted={}, trusted={}, committed={}, virtual={}",
            untrusted_advice_base, trusted_advice_base, committed_base, virtual_base);

        // Try to parse the length of opening claims
        if proof_bytes.len() >= 8 {
            let len_bytes: [u8; 8] = proof_bytes[0..8].try_into().unwrap();
            let claims_len = u64::from_le_bytes(len_bytes);
            println!("\nOpening claims length: {}", claims_len);

            // Try to parse each claim
            let mut offset = 8usize;
            for i in 0..claims_len {
                if offset >= proof_bytes.len() {
                    println!("  Ran out of bytes at claim {}", i);
                    break;
                }

                // Opening ID first byte
                let first_byte = proof_bytes[offset];
                println!("\n  Claim {}: opening_id first byte = 0x{:02x} ({})", i, first_byte, first_byte);
                offset += 1;

                // Decode the opening type
                if first_byte < trusted_advice_base {
                    println!("    Type: UntrustedAdvice({})", first_byte);
                } else if first_byte < committed_base {
                    println!("    Type: TrustedAdvice({})", first_byte - trusted_advice_base);
                } else if first_byte < virtual_base {
                    // Committed - has poly after
                    let sumcheck_id = first_byte - committed_base;
                    println!("    Type: Committed(sumcheck={})", sumcheck_id);
                    if offset < proof_bytes.len() {
                        let poly_byte = proof_bytes[offset];
                        println!("    poly type byte = 0x{:02x} ({})", poly_byte, poly_byte);
                        offset += 1;
                        if poly_byte >= 2 && poly_byte <= 4 && offset < proof_bytes.len() {
                            let idx_byte = proof_bytes[offset];
                            println!("    poly index = {}", idx_byte);
                            offset += 1;
                        }
                    }
                } else {
                    // Virtual - has poly after
                    let sumcheck_id = first_byte - virtual_base;
                    println!("    Type: Virtual(sumcheck={})", sumcheck_id);
                    if offset < proof_bytes.len() {
                        let poly_byte = proof_bytes[offset];
                        println!("    VirtualPoly type = {} (0x{:02x})", poly_byte, poly_byte);
                        offset += 1;
                        // InstructionRa, OpFlags, InstructionFlags, LookupTableFlag have index
                        if poly_byte == 27 || poly_byte == 38 || poly_byte == 39 || poly_byte == 40 {
                            if offset < proof_bytes.len() {
                                let idx_byte = proof_bytes[offset];
                                println!("    poly index = {}", idx_byte);
                                offset += 1;
                            }
                        }
                    }
                }

                // Field element (32 bytes)
                if offset + 32 > proof_bytes.len() {
                    println!("    Not enough bytes for field element!");
                    break;
                }
                let fe_slice = &proof_bytes[offset..offset + 32];
                println!("    claim bytes: {:02x} {:02x} {:02x} {:02x} ...",
                    fe_slice[0], fe_slice[1], fe_slice[2], fe_slice[3]);

                // Try to deserialize as Fr
                match Fr::deserialize_compressed(fe_slice) {
                    Ok(_fe) => println!("    claim: valid Fr"),
                    Err(e) => println!("    claim: INVALID Fr: {:?}", e),
                }
                offset += 32;
            }

            println!("\n\nAfter claims, offset = {}", offset);
            println!("Next section: commitments");

            // Try to parse commitments length
            if offset + 8 <= proof_bytes.len() {
                let comm_len_bytes: [u8; 8] = proof_bytes[offset..offset+8].try_into().unwrap();
                let comm_len = u64::from_le_bytes(comm_len_bytes);
                println!("Commitments length: {}", comm_len);
                offset += 8;

                // Parse GT commitments (384 bytes each)
                for i in 0..comm_len {
                    if offset + 384 > proof_bytes.len() {
                        println!("  Commitment {}: not enough bytes (need 384, have {})",
                            i, proof_bytes.len() - offset);
                        break;
                    }
                    let comm_slice = &proof_bytes[offset..offset+384];
                    println!("  Commitment {}: first bytes {:02x} {:02x} {:02x} {:02x} ...",
                        i, comm_slice[0], comm_slice[1], comm_slice[2], comm_slice[3]);

                    // Try to deserialize as Fq12
                    use ark_serialize::CanonicalDeserialize;
                    use ark_bn254::Fq12;
                    match Fq12::deserialize_uncompressed(comm_slice) {
                        Ok(_) => println!("    Valid GT element"),
                        Err(e) => println!("    INVALID GT: {:?}", e),
                    }
                    offset += 384;
                }

                println!("\nAfter commitments, offset = {}", offset);
                println!("Remaining bytes: {}", proof_bytes.len() - offset);
            }
        }
    }

    /// Export a test Dory commitment for comparison with Zolt
    ///
    /// This commits to a small test polynomial using Jolt's Dory and exports
    /// the resulting GT element so Zolt can compare its commitment.
    #[test]
    #[ignore = "run manually to generate test commitment"]
    fn test_export_dory_commitment() {
        use crate::poly::commitment::dory::{DoryCommitmentScheme, DoryGlobals, DoryContext};
        use crate::poly::commitment::commitment_scheme::CommitmentScheme;
        use crate::poly::multilinear_polynomial::MultilinearPolynomial;
        use ark_serialize::CanonicalSerialize;
        use ark_bn254::Fr;
        use std::io::Write;

        // Simple test polynomial: [1, 2, 3, 4, 5, 6, 7, 8]
        let coeffs: Vec<Fr> = (1u64..=8).map(|i| Fr::from(i)).collect();
        let poly: MultilinearPolynomial<Fr> = coeffs.into();

        // Initialize Dory globals - need K=1 (single polynomial), T=8 (coefficients)
        DoryGlobals::initialize_context(1, 8, DoryContext::Main, None);

        // Setup prover (uses "Jolt Dory URS seed")
        let prover_setup = DoryCommitmentScheme::setup_prover(3); // 2^3 = 8 coefficients

        println!("Dory initialized:");
        println!("  num_columns = {}", DoryGlobals::get_num_columns());
        println!("  max_num_rows = {}", DoryGlobals::get_max_num_rows());

        // Commit
        let (commitment, _row_commitments) = DoryCommitmentScheme::commit(&poly, &prover_setup);

        // Serialize commitment
        let mut buf = Vec::new();
        commitment.serialize_uncompressed(&mut buf).expect("serialize");

        println!("\nCommitment (GT element):");
        println!("  Size: {} bytes", buf.len());
        println!("  First 16 bytes: {:02x?}", &buf[..16]);
        println!("  Last 16 bytes: {:02x?}", &buf[buf.len()-16..]);

        // Write to file
        let output_path = "/tmp/jolt_test_commitment.bin";
        let mut file = std::fs::File::create(output_path).expect("create file");

        // Write header
        file.write_all(b"JOLT_COMM_V1").expect("write header");
        file.write_all(&8u64.to_le_bytes()).expect("write poly_len");

        // Write polynomial coefficients (just the original coeffs)
        for i in 0..8 {
            let coeff = poly.get_coeff(i);
            let mut cbuf = Vec::new();
            coeff.serialize_compressed(&mut cbuf).expect("serialize coeff");
            file.write_all(&cbuf).expect("write coeff");
        }

        // Write commitment
        file.write_all(&buf).expect("write commitment");

        println!("\nExported to {}", output_path);
    }

    /// Export Dory SRS to a file for use by Zolt
    ///
    /// This generates the same SRS that Jolt uses (from "Jolt Dory URS seed")
    /// and serializes it to a file that Zolt can load.
    #[test]
    #[ignore = "run manually to generate SRS file"]
    fn test_export_dory_srs() {
        use crate::poly::commitment::dory::{DoryCommitmentScheme, ArkworksProverSetup};
        use crate::poly::commitment::commitment_scheme::CommitmentScheme;
        use ark_serialize::CanonicalSerialize;
        use ark_ec::CurveGroup;
        use std::io::Write;

        use crate::poly::commitment::dory::{DoryGlobals, DoryContext};

        // Generate SRS matching the fibonacci program:
        // Jolt's JoltProverPreprocessing::new() computes:
        //   max_padded_trace_length = 65536 (from compiled program)
        //   max_T = 65536, max_log_T = 16
        //   max_log_k_chunk = 4 (since 16 < ONEHOT_CHUNK_THRESHOLD_LOG_T=25)
        //   max_num_vars = 4 + 16 = 20
        // The max_num_vars determines which cached .urs file is used.
        let max_num_vars = 20;
        println!("Generating Dory SRS with max_num_vars = {}", max_num_vars);

        // Initialize DoryGlobals
        DoryGlobals::initialize_context(1 << 4, 1 << 16, DoryContext::Main, None);

        let prover_setup: ArkworksProverSetup = DoryCommitmentScheme::setup_prover(max_num_vars);

        // Export to file
        let output_path = "/tmp/jolt_dory_srs.bin";
        let mut file = std::fs::File::create(output_path).expect("create file");

        // Write header
        file.write_all(b"JOLT_DORY_SRS_V1").expect("write header");
        file.write_all(&(max_num_vars as u64).to_le_bytes()).expect("write num vars");

        // Write G1 points count and data
        let g1_count = prover_setup.g1_vec.len() as u64;
        file.write_all(&g1_count.to_le_bytes()).expect("write g1 count");
        println!("Writing {} G1 points", g1_count);

        for (i, g1) in prover_setup.g1_vec.iter().enumerate() {
            // Convert projective to affine before serializing
            let g1_affine: ark_bn254::G1Affine = g1.0.into_affine();
            let mut buf = Vec::new();
            g1_affine.serialize_uncompressed(&mut buf).expect("serialize G1");
            file.write_all(&buf).expect("write G1");
            if i < 3 {
                println!("  G1[{}]: {} bytes, first 8: {:02x?}", i, buf.len(), &buf[..8]);
            }
        }

        // Write G2 points count and data
        let g2_count = prover_setup.g2_vec.len() as u64;
        file.write_all(&g2_count.to_le_bytes()).expect("write g2 count");
        println!("Writing {} G2 points", g2_count);

        for (i, g2) in prover_setup.g2_vec.iter().enumerate() {
            // Convert projective to affine before serializing
            let g2_affine: ark_bn254::G2Affine = g2.0.into_affine();
            let mut buf = Vec::new();
            g2_affine.serialize_uncompressed(&mut buf).expect("serialize G2");
            file.write_all(&buf).expect("write G2");
            if i < 3 {
                println!("  G2[{}]: {} bytes, first 8: {:02x?}", i, buf.len(), &buf[..8]);
            }
        }

        // Write blinding generators (convert projective to affine)
        let h1_affine: ark_bn254::G1Affine = prover_setup.h1.0.into_affine();
        let mut buf = Vec::new();
        h1_affine.serialize_uncompressed(&mut buf).expect("serialize h1");
        file.write_all(&buf).expect("write h1");
        println!("h1: {} bytes", buf.len());

        let h2_affine: ark_bn254::G2Affine = prover_setup.h2.0.into_affine();
        buf.clear();
        h2_affine.serialize_uncompressed(&mut buf).expect("serialize h2");
        file.write_all(&buf).expect("write h2");
        println!("h2: {} bytes", buf.len());
        println!("h2 uncompressed hex: {}", buf.iter().map(|b| format!("{:02x}", b)).collect::<Vec<_>>().join(""));

        // Also print h2 compressed for comparison with Zolt
        let mut h2_compressed = Vec::new();
        h2_affine.serialize_compressed(&mut h2_compressed).expect("serialize h2 compressed");
        println!("h2 compressed hex ({} bytes): {}", h2_compressed.len(), h2_compressed.iter().map(|b| format!("{:02x}", b)).collect::<Vec<_>>().join(""));

        // Print h1 details too
        let mut h1_compressed = Vec::new();
        h1_affine.serialize_compressed(&mut h1_compressed).expect("serialize h1 compressed");
        println!("h1 compressed hex ({} bytes): {}", h1_compressed.len(), h1_compressed.iter().map(|b| format!("{:02x}", b)).collect::<Vec<_>>().join(""));

        // Also export the verifier setup h2 to verify it matches
        let verifier_setup = prover_setup.to_verifier_setup();
        let vs_h2_affine: ark_bn254::G2Affine = verifier_setup.h2.0.into_affine();
        let mut vs_h2_compressed = Vec::new();
        vs_h2_affine.serialize_compressed(&mut vs_h2_compressed).expect("serialize vs h2 compressed");
        println!("verifier_setup.h2 compressed hex: {}", vs_h2_compressed.iter().map(|b| format!("{:02x}", b)).collect::<Vec<_>>().join(""));

        println!("\nExported Dory SRS to {}", output_path);
        println!("Total file size: {} bytes", std::fs::metadata(output_path).expect("stat").len());
    }

    /// Export detailed Dory commitment intermediate values
    ///
    /// This test exports the MSM result (row commitment) and pairing result
    /// so we can compare intermediate values with Zolt.
    #[test]
    #[ignore = "run manually to debug commitment"]
    fn test_export_dory_commitment_debug() {
        use crate::poly::commitment::dory::{DoryCommitmentScheme, DoryGlobals, DoryContext};
        use crate::poly::commitment::commitment_scheme::CommitmentScheme;
        use crate::poly::multilinear_polynomial::MultilinearPolynomial;
        use ark_serialize::CanonicalSerialize;
        use ark_bn254::{Fr, G1Affine, G2Affine, Bn254};
        use ark_ec::{pairing::Pairing, VariableBaseMSM, CurveGroup};
        use std::io::Write;

        // Simple test polynomial: [1, 2, 3, 4, 5, 6, 7, 8]
        let coeffs: Vec<Fr> = (1u64..=8).map(|i| Fr::from(i)).collect();
        let poly: MultilinearPolynomial<Fr> = coeffs.into();

        // Initialize Dory globals - need K=1 (single polynomial), T=8 (coefficients)
        DoryGlobals::initialize_context(1, 8, DoryContext::Main, None);

        // Setup prover (uses "Jolt Dory URS seed")
        let prover_setup = DoryCommitmentScheme::setup_prover(3); // 2^3 = 8 coefficients

        let num_cols = DoryGlobals::get_num_columns();
        let num_rows = DoryGlobals::get_max_num_rows();
        let sigma = num_cols.ilog2() as usize;
        let nu = num_rows.ilog2() as usize;

        println!("Dory commitment debug:");
        println!("  sigma = {} (num_cols = {})", sigma, num_cols);
        println!("  nu = {} (num_rows = {})", nu, num_rows);

        // Print first 4 G1 points for debugging
        println!("\nG1 points in SRS:");
        for i in 0..4 {
            let g1_i: G1Affine = prover_setup.g1_vec[i].0.into_affine();
            let mut buf = Vec::new();
            g1_i.serialize_uncompressed(&mut buf).expect("serialize");
            println!("  G1[{}] x first 16: {:02x?}, y first 16: {:02x?}", i, &buf[..16], &buf[32..48]);
            // Print y coordinate as decimal to verify it's < modulus
            use ark_ff::PrimeField;
            let y_int = g1_i.y.into_bigint();
            let y_limbs = y_int.0;
            println!("    y limbs: {:016x} {:016x} {:016x} {:016x}",
                y_limbs[0], y_limbs[1], y_limbs[2], y_limbs[3]);
        }

        // Test: G1[0] * 2
        let g1_0: G1Affine = prover_setup.g1_vec[0].0.into_affine();
        let scalar_2 = Fr::from(2u64);
        let g1_times_2: ark_bn254::G1Projective = VariableBaseMSM::msm_unchecked(&[g1_0], &[scalar_2]);
        let g1_times_2_affine: G1Affine = g1_times_2.into_affine();
        let mut buf = Vec::new();
        g1_times_2_affine.serialize_uncompressed(&mut buf).expect("serialize");
        println!("\nG1[0]*2 x first 16 bytes: {:02x?}", &buf[..16]);

        // Test: G1[0]*1 + G1[1]*1 (adding two points)
        let g1_1: G1Affine = prover_setup.g1_vec[1].0.into_affine();
        let scalar_1 = Fr::from(1u64);
        let g1_sum: ark_bn254::G1Projective = VariableBaseMSM::msm_unchecked(&[g1_0, g1_1], &[scalar_1, scalar_1]);
        let g1_sum_affine: G1Affine = g1_sum.into_affine();
        buf.clear();
        g1_sum_affine.serialize_uncompressed(&mut buf).expect("serialize");
        println!("G1[0]+G1[1] x first 16 bytes: {:02x?}", &buf[..16]);

        // Get G1 generators as affine (taking first num_cols)
        let g1_bases: Vec<G1Affine> = prover_setup.g1_vec[..num_cols]
            .iter()
            .map(|g| g.0.into_affine())
            .collect();

        // Get G2 generators as affine
        let g2_bases: Vec<G2Affine> = prover_setup.g2_vec[..num_rows]
            .iter()
            .map(|g| g.0.into_affine())
            .collect();

        // Print G2 points for debugging
        println!("\nG2 points in SRS:");
        for i in 0..2 {
            let g2_i: G2Affine = prover_setup.g2_vec[i].0.into_affine();
            let mut buf = Vec::new();
            g2_i.serialize_uncompressed(&mut buf).expect("serialize");

            // Print all 4 Fp components: x.c0, x.c1, y.c0, y.c1
            println!("  G2[{}]:", i);
            println!("    x.c0 first 16: {:02x?}", &buf[0..16]);
            println!("    x.c1 first 16: {:02x?}", &buf[32..48]);
            println!("    y.c0 first 16: {:02x?}", &buf[64..80]);
            println!("    y.c1 first 16: {:02x?}", &buf[96..112]);
        }

        // Test: Pairing of G1 generator with G2 generator
        use ark_ec::AffineRepr;
        let g1_gen = G1Affine::generator();
        let g2_gen = G2Affine::generator();

        // Print G2 generator coordinates
        println!("\nG2 generator:");
        let mut g2_buf = Vec::new();
        g2_gen.serialize_uncompressed(&mut g2_buf).expect("serialize");
        println!("  x.c0 first 16: {:02x?}", &g2_buf[0..16]);
        println!("  x.c1 first 16: {:02x?}", &g2_buf[32..48]);
        println!("  y.c0 first 16: {:02x?}", &g2_buf[64..80]);
        println!("  y.c1 first 16: {:02x?}", &g2_buf[96..112]);

        let gen_pairing = Bn254::pairing(g1_gen, g2_gen);
        let mut buf_gen = Vec::new();
        gen_pairing.0.serialize_uncompressed(&mut buf_gen).expect("serialize");
        println!("\ne(G1_gen, G2_gen) first 16 bytes: {:02x?}", &buf_gen[..16]);

        // Output file for debug info
        let output_path = "/tmp/jolt_dory_debug.bin";
        let mut file = std::fs::File::create(output_path).expect("create file");

        // Write header
        file.write_all(b"JOLT_DORY_DBG1").expect("write header");
        file.write_all(&(num_cols as u64).to_le_bytes()).expect("write num_cols");
        file.write_all(&(num_rows as u64).to_le_bytes()).expect("write num_rows");

        // Compute row commitments and export them
        println!("\nRow commitments (G1 MSM results):");
        let mut row_commits: Vec<G1Affine> = Vec::new();

        for row_idx in 0..num_rows {
            let start = row_idx * num_cols;
            let end = std::cmp::min(start + num_cols, 8);

            // Get coefficients for this row
            let row_coeffs: Vec<Fr> = (start..end)
                .map(|i| if i < 8 { Fr::from((i + 1) as u64) } else { Fr::from(0u64) })
                .collect();

            println!("  Row {}: start={}, end={}, coeffs={:?}", row_idx, start, end,
                row_coeffs.iter().map(|f| {
                    let mut buf = [0u8; 32];
                    f.serialize_compressed(&mut buf[..]).ok();
                    buf[0] as u64  // Just show low byte
                }).collect::<Vec<_>>()
            );

            // Compute MSM
            let row_commit: ark_bn254::G1Projective = VariableBaseMSM::msm_unchecked(&g1_bases[..row_coeffs.len()], &row_coeffs);
            let row_commit_affine: G1Affine = row_commit.into_affine();
            row_commits.push(row_commit_affine);

            // Serialize row commitment
            let mut buf = Vec::new();
            row_commit_affine.serialize_uncompressed(&mut buf).expect("serialize");
            file.write_all(&buf).expect("write row commitment");

            println!("    G1 result first 16 bytes: {:02x?}", &buf[..16]);
        }

        // Compute individual pairings and the final multi-pairing
        println!("\nIndividual pairings:");
        for (i, (g1, g2)) in row_commits.iter().zip(g2_bases.iter()).enumerate() {
            let paired = Bn254::pairing(*g1, *g2);
            let mut buf = Vec::new();
            paired.0.serialize_uncompressed(&mut buf).expect("serialize");
            file.write_all(&buf).expect("write pairing");
            println!("  Pairing({}, {}) first 16 bytes: {:02x?}", i, i, &buf[..16]);
        }

        // Compute multi-pairing (should be equivalent to product of individual pairings)
        let multi_pairing = Bn254::multi_pairing(&row_commits, &g2_bases);
        let mut buf = Vec::new();
        multi_pairing.0.serialize_uncompressed(&mut buf).expect("serialize");
        file.write_all(&buf).expect("write multi pairing");
        println!("\nMulti-pairing first 16 bytes: {:02x?}", &buf[..16]);

        // Also compute product of individual pairings for comparison
        let mut product = Bn254::pairing(row_commits[0], g2_bases[0]);
        for i in 1..row_commits.len() {
            product = product + Bn254::pairing(row_commits[i], g2_bases[i]);
        }
        let mut buf = Vec::new();
        product.0.serialize_uncompressed(&mut buf).expect("serialize");
        println!("Product of pairings first 16 bytes: {:02x?}", &buf[..16]);

        println!("\nExported debug info to {}", output_path);
    }

    /// Debug Stage 4 verification - print input claims and first round poly
    #[test]
    #[ignore = "requires Zolt proof file - run manually"]
    fn test_debug_stage4_verification() {
        use crate::zkvm::{RV64IMACProof, Serializable};

        let proof_path = "/tmp/zolt_proof_dory.bin";

        // Load proof
        let proof_bytes = fs::read(&proof_path).expect("Failed to read proof");
        let proof = RV64IMACProof::deserialize_from_bytes(&proof_bytes)
            .expect("Failed to deserialize proof");

        println!("Loaded proof:");
        println!("  Trace length: {}", proof.trace_length);
        println!("  RAM K: {}", proof.ram_K);
        println!("  Stage 4 sumcheck: {} rounds", proof.stage4_sumcheck_proof.compressed_polys.len());

        // Print first round polynomial of Stage 4
        println!("\nStage 4 round polynomials:");
        for (round, poly) in proof.stage4_sumcheck_proof.compressed_polys.iter().enumerate() {
            use ark_ff::PrimeField;
            print!("  Round {}: [", round);
            for (i, coeff) in poly.coeffs_except_linear_term.iter().enumerate() {
                let limbs = coeff.into_bigint().0;
                if i > 0 { print!(", "); }
                // Print truncated value for readability
                print!("{:08x}...", limbs[0] & 0xFFFFFFFF);
            }
            println!("]");
        }

        // Print all opening claims for debugging
        println!("\nAll opening claims ({}):", proof.opening_claims.0.len());
        for (key, (_, claim)) in proof.opening_claims.0.iter() {
            use ark_ff::PrimeField;
            let limbs = claim.into_bigint().0;
            println!("  {:?} = {:08x}...", key, limbs[0] & 0xFFFFFFFF);
        }
    }

    /// Detailed Stage 4 sumcheck debug - manually replay verification
    #[test]
    #[ignore = "requires Zolt proof and preprocessing - run manually"]
    fn test_debug_stage4_sumcheck_detailed() {
        use crate::zkvm::{RV64IMACProof, RV64IMACVerifier};
        use crate::zkvm::verifier::JoltVerifierPreprocessing;
        use crate::poly::commitment::dory::DoryCommitmentScheme;
        use common::jolt_device::JoltDevice;
        use ark_ff::PrimeField;

        type PreprocessingType = JoltVerifierPreprocessing<ark_bn254::Fr, DoryCommitmentScheme>;
        type Fr = ark_bn254::Fr;

        // Load files (same as test_verify_zolt_proof_with_zolt_preprocessing)
        let logs_dir = std::env::var("ZOLT_LOGS_DIR").unwrap_or_else(|_| {
            let local_logs = std::path::Path::new("../zolt/logs");
            if local_logs.exists() {
                local_logs.to_string_lossy().to_string()
            } else {
                "/tmp".to_string()
            }
        });
        let preprocessing_path = format!("{}/zolt_preprocessing.bin", logs_dir);
        let proof_path = format!("{}/zolt_proof_dory.bin", logs_dir);

        // Check files exist
        for path in [preprocessing_path.as_str(), proof_path.as_str()] {
            if !Path::new(path).exists() {
                println!("Missing required file: {}", path);
                return;
            }
        }

        // Load preprocessing
        let preprocessing_bytes = fs::read(&preprocessing_path)
            .expect("Failed to read preprocessing");
        let preprocessing = PreprocessingType::deserialize_from_bytes(&preprocessing_bytes)
            .expect("Failed to deserialize preprocessing");

        // Load proof
        let proof_bytes = fs::read(&proof_path).expect("Failed to read proof");
        let proof = RV64IMACProof::deserialize_from_bytes(&proof_bytes)
            .expect("Failed to deserialize proof");

        // Create minimal program I/O
        let program_io = JoltDevice {
            memory_layout: preprocessing.shared.memory_layout.clone(),
            ..Default::default()
        };

        println!("=== Stage 4 Sumcheck Debug ===");
        println!("Trace length: {}", proof.trace_length);
        println!("Number of Stage 4 rounds: {}", proof.stage4_sumcheck_proof.compressed_polys.len());

        // Print first few round polynomials with full details
        println!("\nRound polynomials from proof:");
        for (round, poly) in proof.stage4_sumcheck_proof.compressed_polys.iter().enumerate().take(3) {
            println!("  Round {}: {} coefficients", round, poly.coeffs_except_linear_term.len());
            for (i, coeff) in poly.coeffs_except_linear_term.iter().enumerate() {
                let limbs = coeff.into_bigint().0;
                println!("    coeffs_except_linear[{}] = {:016x}{:016x}{:016x}{:016x}",
                    i, limbs[3], limbs[2], limbs[1], limbs[0]);
            }
        }

        // Create verifier and run through stages 1-3 to get correct transcript state
        let verifier = RV64IMACVerifier::new(
            &preprocessing,
            proof,
            program_io,
            None,
            None,
        ).expect("Failed to create verifier");

        // The verifier state after stage 3 would give us the correct claims
        // But for now, just print what we have
        println!("\n=== End Stage 4 Debug ===");
    }

}

#[test]
fn test_from_bigint_unchecked_behavior() {
    use ark_bn254::Fr;
    use ark_ff::{BigInt, PrimeField};
    use ark_serialize::CanonicalSerialize;

    // Test: from_bigint_unchecked([0, 0, 1, 0])
    // This is how MontU128Challenge converts to Fr
    let bigint = BigInt::new([0, 0, 1, 0]);
    let fr = Fr::from_bigint_unchecked(bigint).unwrap();

    println!("from_bigint_unchecked([0, 0, 1, 0]):");
    println!("  result = {:?}", fr);
    println!("  is_one = {}", fr == Fr::from(1u64));

    // Serialize and print the bytes
    let mut bytes = [0u8; 32];
    fr.serialize_compressed(&mut bytes[..]).unwrap();
    println!("  serialized (LE): {:02x?}", bytes);

    // Now test with a known challenge value
    // Use the same value that appeared in our debug: low=0x0d8d89b0c0ef00b0, high=0x84a48a1b0b143407
    let low: u64 = 0x0d8d89b0c0ef00b0;
    let high: u64 = 0x84a48a1b0b143407;
    let bigint2 = BigInt::new([0, 0, low, high]);
    let fr2 = Fr::from_bigint_unchecked(bigint2).unwrap();

    println!("\nfrom_bigint_unchecked([0, 0, {:#x}, {:#x}]):", low, high);
    let mut bytes2 = [0u8; 32];
    fr2.serialize_compressed(&mut bytes2[..]).unwrap();
    println!("  serialized (LE): {:02x?}", bytes2);

    // Compare with from_bigint (which does Montgomery conversion)
    // Use a smaller value that fits: [low, high, 0, 0]
    let bigint_small = BigInt::new([low, high, 0, 0]);
    let fr3 = Fr::from_bigint(bigint_small).unwrap();
    let mut bytes3 = [0u8; 32];
    fr3.serialize_compressed(&mut bytes3[..]).unwrap();
    println!("from_bigint([{:#x}, {:#x}, 0, 0]):", low, high);
    println!("  serialized (LE): {:02x?}", bytes3);

    // Now compare with from_bigint_unchecked([low, high, 0, 0])
    let bigint_small_unchecked = BigInt::new([low, high, 0, 0]);
    let fr4 = Fr::from_bigint_unchecked(bigint_small_unchecked).unwrap();
    let mut bytes4 = [0u8; 32];
    fr4.serialize_compressed(&mut bytes4[..]).unwrap();
    println!("from_bigint_unchecked([{:#x}, {:#x}, 0, 0]):", low, high);
    println!("  serialized (LE): {:02x?}", bytes4);

    // For small values [low, high, 0, 0]:
    // - from_bigint: input is standard form, output is that value in Montgomery form
    // - from_bigint_unchecked: input IS Montgomery form, output is input/R in standard form when serialized
    // So these should be DIFFERENT!
    assert_ne!(bytes3, bytes4, "from_bigint and from_bigint_unchecked should differ for same input");

    assert!(fr != Fr::from(1u64), "from_bigint_unchecked should NOT equal Fr::from(1)");
}

#[test]
fn test_zolt_gt_deserialization() {
    use ark_serialize::CanonicalDeserialize;
    use ark_bn254::Fq12;
    use std::fs;
    use std::path::Path;

    let gt_path = "/tmp/zolt_gt_test.bin";
    if !Path::new(gt_path).exists() {
        println!("No GT test file at {}", gt_path);
        return;
    }

    let gt_bytes = fs::read(gt_path).expect("read GT");
    println!("GT bytes ({} bytes): {:02x?}", gt_bytes.len(), &gt_bytes[..32]);

    // Try compressed deserialization
    match Fq12::deserialize_compressed(&gt_bytes[..]) {
        Ok(gt) => {
            println!("Compressed deserialization OK!");
            println!("GT value: {:?}", gt);
        }
        Err(e) => {
            println!("Compressed deserialization FAILED: {:?}", e);
        }
    }

    // Try uncompressed deserialization
    match Fq12::deserialize_uncompressed(&gt_bytes[..]) {
        Ok(gt) => {
            println!("Uncompressed deserialization OK!");
            println!("GT value: {:?}", gt);
        }
        Err(e) => {
            println!("Uncompressed deserialization FAILED: {:?}", e);
        }
    }
}

#[test]
fn test_zolt_g2_compressed_points() {
    use ark_bn254::{G2Affine, G2Projective, Fq2, Fq};
    use ark_ec::{AffineRepr, CurveGroup};
    use ark_ec::short_weierstrass::SWCurveConfig;
    use ark_serialize::{CanonicalDeserialize, CanonicalSerialize};
    use std::io::Cursor;
    use ark_ff::PrimeField;

    // Read the test points file generated by Zolt
    let data = match std::fs::read("/tmp/zolt_g2_test_points.bin") {
        Ok(d) => d,
        Err(e) => {
            println!("Could not read /tmp/zolt_g2_test_points.bin: {:?}", e);
            println!("Run Zolt's 'g2 compressed bytes for arkworks validation' test first");
            return;
        }
    };

    assert_eq!(data.len(), 192, "Expected 3 G2 points * 64 bytes = 192 bytes");

    let names = ["generator", "[2]G2", "[42]G2"];
    for i in 0..3 {
        let point_bytes = &data[i * 64..(i + 1) * 64];
        println!("\n=== G2 point: {} ===", names[i]);
        println!("Compressed bytes: {:02x?}", point_bytes);

        let mut cursor = Cursor::new(point_bytes);
        match G2Affine::deserialize_compressed(&mut cursor) {
            Ok(pt) => {
                println!("  Deserialized OK!");
                println!("  Is on curve: {}", pt.is_on_curve());
                println!("  Is in subgroup: {}", pt.is_in_correct_subgroup_assuming_on_curve());
            }
            Err(e) => {
                println!("  DESERIALIZATION FAILED: {:?}", e);

                // Try to manually parse and check
                let flag = point_bytes[63] >> 6;
                println!("  Flag: {} (0=YisPos, 2=YisNeg, 1=Infinity)", flag);

                // Read x.c0 and x.c1
                let mut x_bytes = point_bytes.to_vec();
                x_bytes[63] &= 0x3F; // clear flags

                // Manually construct the Fq2 x-coordinate
                let x_c0 = Fq::from_le_bytes_mod_order(&x_bytes[0..32]);
                let x_c1 = Fq::from_le_bytes_mod_order(&x_bytes[32..64]);
                let x = Fq2::new(x_c0, x_c1);
                println!("  x.c0 = {:?}", x_c0);
                println!("  x.c1 = {:?}", x_c1);

                // Check if x^3 + b_twist has a sqrt
                let b_twist = <ark_bn254::g2::Config as SWCurveConfig>::COEFF_B;
                let y_squared = x * x * x + b_twist;
                println!("  y^2 = x^3 + b = {:?}", y_squared);

                // Try to recover y
                use ark_ff::Field;
                if let Some(y) = y_squared.sqrt() {
                    println!("  y (recovered) = {:?}", y);
                    // Use new_unchecked to avoid assertion panic
                    let pt_manual = G2Affine::new_unchecked(x, y);
                    println!("  On curve: {}", pt_manual.is_on_curve());
                    println!("  In subgroup: {}", pt_manual.is_in_correct_subgroup_assuming_on_curve());
                    let neg_pt = G2Affine::new_unchecked(x, -y);
                    println!("  -y In subgroup: {}", neg_pt.is_in_correct_subgroup_assuming_on_curve());
                } else {
                    println!("  NO SQRT EXISTS for y^2 - point x is not on curve!");
                }
            }
        }
    }

    // Also generate the expected G2 generator compressed bytes from arkworks
    println!("\n=== Reference: arkworks G2 generator ===");
    let g2_gen = G2Affine::generator();
    let mut gen_bytes = Vec::new();
    g2_gen.serialize_compressed(&mut gen_bytes).unwrap();
    println!("Arkworks G2 generator compressed ({} bytes): {:02x?}", gen_bytes.len(), &gen_bytes[..]);

    // And [2]G2
    let two_g2 = (G2Projective::from(g2_gen) + G2Projective::from(g2_gen)).into_affine();
    let mut two_bytes = Vec::new();
    two_g2.serialize_compressed(&mut two_bytes).unwrap();
    println!("Arkworks [2]G2 compressed: {:02x?}", &two_bytes[..]);

    // And [42]G2
    let scalar_42 = ark_bn254::Fr::from(42u64);
    let g2_42 = (G2Projective::from(g2_gen) * scalar_42).into_affine();
    let mut bytes_42 = Vec::new();
    g2_42.serialize_compressed(&mut bytes_42).unwrap();
    println!("Arkworks [42]G2 compressed: {:02x?}", &bytes_42[..]);

    // Test the specific failing e2_beta from the proof
    println!("\n=== Testing specific e2_beta from proof ===");
    if let Ok(e2_data) = std::fs::read("/tmp/zolt_g2_test_e2beta.bin") {
        if e2_data.len() == 64 {
            println!("e2_beta bytes: {:02x?}", &e2_data[..]);
            let mut e2_cursor = Cursor::new(&e2_data[..]);
            match G2Affine::deserialize_compressed(&mut e2_cursor) {
                Ok(pt) => {
                    println!("  e2_beta Deserialized OK!");
                    println!("  Is on curve: {}", pt.is_on_curve());
                    println!("  Is in subgroup: {}", pt.is_in_correct_subgroup_assuming_on_curve());
                }
                Err(e) => {
                    println!("  e2_beta DESERIALIZATION FAILED: {:?}", e);
                    // Manual analysis
                    let flag = e2_data[63] >> 6;
                    println!("  Flag: {} (0=YisPos, 2=YisNeg, 1=Infinity)", flag);
                    let mut x_bytes = e2_data.to_vec();
                    x_bytes[63] &= 0x3F;
                    let x_c0 = Fq::from_le_bytes_mod_order(&x_bytes[0..32]);
                    let x_c1 = Fq::from_le_bytes_mod_order(&x_bytes[32..64]);
                    let x = Fq2::new(x_c0, x_c1);
                    println!("  x = {:?}", x);

                    // Check curve equation
                    let b_twist = <ark_bn254::g2::Config as SWCurveConfig>::COEFF_B;
                    let y_squared = x * x * x + b_twist;
                    use ark_ff::Field;
                    if let Some(y) = y_squared.sqrt() {
                        println!("  y (recovered) = {:?}", y);
                        let pt_manual = G2Affine::new_unchecked(x, y);
                        println!("  On curve: {}", pt_manual.is_on_curve());
                        println!("  In subgroup: {}", pt_manual.is_in_correct_subgroup_assuming_on_curve());
                        let neg_y_pt = G2Affine::new_unchecked(x, -y);
                        println!("  -y In subgroup: {}", neg_y_pt.is_in_correct_subgroup_assuming_on_curve());
                    } else {
                        println!("  NO SQRT for y^2 - x is not on G2 curve!");
                    }
                }
            }
        }
    }

    // Compare Zolt vs arkworks for generator
    println!("\n=== COMPARISON ===");
    if data[0..64] == gen_bytes[..] {
        println!("G2 GENERATOR: MATCH!");
    } else {
        println!("G2 GENERATOR: MISMATCH!");
    }
    if data[64..128] == two_bytes[..] {
        println!("[2]G2: MATCH!");
    } else {
        println!("[2]G2: MISMATCH!");
    }
    if data[128..192] == bytes_42[..] {
        println!("[42]G2: MATCH!");
    } else {
        println!("[42]G2: MISMATCH!");
    }

    // Check SRS G2 points
    println!("\n=== Checking SRS G2 points ===");
    if let Ok(srs_data) = std::fs::read("/tmp/zolt_g2_srs_points.bin") {
        let count = u32::from_le_bytes(srs_data[0..4].try_into().unwrap()) as usize;
        println!("SRS has {} G2 points", count);
        let mut failed = 0;
        let mut passed = 0;
        for i in 0..count {
            let point_bytes = &srs_data[4 + i * 64..4 + (i + 1) * 64];
            let mut cursor = Cursor::new(point_bytes);
            match G2Affine::deserialize_compressed(&mut cursor) {
                Ok(_pt) => { passed += 1; }
                Err(e) => {
                    if failed < 5 {
                        println!("  SRS G2[{}] FAILED: {:?}", i, e);
                    }
                    failed += 1;
                }
            }
        }
        println!("SRS G2 results: {} passed, {} failed", passed, failed);
    }

    // Check MSM result
    println!("\n=== Checking MSM result ===");
    if let Ok(msm_data) = std::fs::read("/tmp/zolt_g2_msm_test.bin") {
        let mut cursor = Cursor::new(&msm_data[..]);
        match G2Affine::deserialize_compressed(&mut cursor) {
            Ok(_pt) => {
                println!("  MSM G2 result: OK (in subgroup)");
            }
            Err(e) => {
                println!("  MSM G2 result: FAILED: {:?}", e);
            }
        }
    }
}
